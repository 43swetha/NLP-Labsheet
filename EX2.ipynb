{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name:Swetha.K\n",
    "Roll No:235229143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "min_df=1, ngram_range=(1, 1)\n",
      "Feature names: ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "Transformed data:\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "\n",
      "min_df=1, ngram_range=(1, 2)\n",
      "Feature names: ['and', 'and this', 'document', 'document is', 'first', 'first document', 'is', 'is the', 'is this', 'one', 'second', 'second document', 'the', 'the first', 'the second', 'the third', 'third', 'third one', 'this', 'this document', 'this is', 'this the']\n",
      "Transformed data:\n",
      "[[0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      " [0 0 2 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0]\n",
      " [1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0]\n",
      " [0 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1]]\n",
      "\n",
      "min_df=1, ngram_range=(2, 2)\n",
      "Feature names: ['and this', 'document is', 'first document', 'is the', 'is this', 'second document', 'the first', 'the second', 'the third', 'third one', 'this document', 'this is', 'this the']\n",
      "Transformed data:\n",
      "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n",
      "\n",
      "min_df=2, ngram_range=(1, 1)\n",
      "Feature names: ['document', 'first', 'is', 'the', 'this']\n",
      "Transformed data:\n",
      "[[1 1 1 1 1]\n",
      " [2 0 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "\n",
      "min_df=2, ngram_range=(1, 2)\n",
      "Feature names: ['document', 'first', 'first document', 'is', 'is the', 'the', 'the first', 'this', 'this is']\n",
      "Transformed data:\n",
      "[[1 1 1 1 1 1 1 1 1]\n",
      " [2 0 0 1 1 1 0 1 0]\n",
      " [0 0 0 1 1 1 0 1 1]\n",
      " [1 1 1 1 0 1 1 1 0]]\n",
      "\n",
      "min_df=2, ngram_range=(2, 2)\n",
      "Feature names: ['first document', 'is the', 'the first', 'this is']\n",
      "Transformed data:\n",
      "[[1 1 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 1]\n",
      " [1 0 1 0]]\n",
      "\n",
      "min_df=3, ngram_range=(1, 1)\n",
      "Feature names: ['document', 'is', 'the', 'this']\n",
      "Transformed data:\n",
      "[[1 1 1 1]\n",
      " [2 1 1 1]\n",
      " [0 1 1 1]\n",
      " [1 1 1 1]]\n",
      "\n",
      "min_df=3, ngram_range=(1, 2)\n",
      "Feature names: ['document', 'is', 'is the', 'the', 'this']\n",
      "Transformed data:\n",
      "[[1 1 1 1 1]\n",
      " [2 1 1 1 1]\n",
      " [0 1 1 1 1]\n",
      " [1 1 0 1 1]]\n",
      "\n",
      "min_df=3, ngram_range=(2, 2)\n",
      "Feature names: ['is the']\n",
      "Transformed data:\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample text data\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "# Try different values of min_df and ngram_range\n",
    "min_df_values = [1, 2, 3]  # Minimum document frequency\n",
    "ngram_range_values = [(1, 1), (1, 2), (2, 2)]  # Range of n-grams\n",
    "\n",
    "for min_df in min_df_values:\n",
    "    for ngram_range in ngram_range_values:\n",
    "        vectorizer = CountVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "        print(f\"\\nmin_df={min_df}, ngram_range={ngram_range}\")\n",
    "        print(\"Feature names:\", vectorizer.get_feature_names())\n",
    "        print(\"Transformed data:\")\n",
    "        print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
